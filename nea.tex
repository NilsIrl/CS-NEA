\documentclass{article}

\usepackage[utf8]{inputenc}
%\usepackage{fontspec}
\usepackage{newunicodechar}
\newunicodechar{”}{''}
\newunicodechar{“}{``}
%\newunicodechar{♙}{\fontspec{Noto Color Emoji}\char"2659}
%\DeclareUnicodeCharacter{201D}{''}
%\DeclareUnicodeCharacter{201D}{``}
%\DeclareUnicodeCharacter{2654}{}
\usepackage[T1]{fontenc}

\usepackage{graphicx}
\graphicspath{ {./tex_assets/} }

\usepackage{import}
\usepackage[british]{babel}

\usepackage{hyperref}
\usepackage{biblatex}
\addbibresource{nea.bib}

\usepackage{adjustbox}
\usepackage{makecell}
\usepackage{tikz}

\usepackage[color={1 0 0}]{attachfile2}
\usepackage{ifluatex}

\definecolor{bg}{rgb}{0.95,0.95,0.95}
\ifluatex
% Lualatex
\usepackage[outputdir=build]{minted}
\newcommand{\inputmintedgrey}[2]{\inputminted[bgcolor=bg]{#1}{#2}}
\else
% Tectonic
\usepackage[]{minted}
\usepackage{letltxmacro}

% redefine \inputminted to work with tectonic
\LetLtxMacro{\oldinputminted}{\inputminted}
\renewcommand{\inputminted}[2]{\oldinputminted{#1}{/Users/nils/git/CS-NEA/#2}}
\newcommand{\inputmintedgrey}[2]{\oldinputminted[bgcolor=bg]{#1}{/Users/nils/git/CS-NEA/#2}}
\fi

\setminted{tabsize=4}


\usetikzlibrary{shapes.geometric, shapes.misc, arrows, calc, decorations.markings, positioning}

\newcommand{\midarrow}{\tikz \draw[-stealth,thick] (0,0) -- +(.1,0);}

\tikzstyle{flowchartbox} = [text centered, draw, minimum width=3cm, minimum height=1cm]
\tikzstyle{terminal} = [flowchartbox, rectangle, rounded rectangle]
\tikzstyle{process} = [flowchartbox, rectangle]
\tikzstyle{decision} = [draw, diamond, text width=6em, align = flush center,
inner sep = 0pt]
\tikzstyle{io} = [flowchartbox, trapezium, trapezium stretches=true, trapezium left angle=70, trapezium right angle=110]
\tikzstyle{flowchartarrow} = [->,thick,>=stealth]
\tikzstyle{flowchartline} = [thick]

\author{Nils André-Chang}
\title{NEA: OCR Exam Reference Language as a Language, an implementation}
\date{14th March 2022}

\begin{document}

{\huge THIS COPY OF THE DOCUMENT IS A DRAFT AND IS NOT MEANT TO BE MARKED}

\maketitle

\tableofcontents

\listoffigures

\listoflistings

\listoftables

In this document, the author refers to themselves as `we' however, there is
only a singular author, and the use of this pronoun is not meant as an
indication of there being multiple authors.

An implementation of the OCR Exam Reference Language as defined by
\textcite{j277, h446}.

\section{Analysis}

\subsection{The problem and its computational solution}

Every year in the UK, thousands of students take computer science as a subject
for their secondary school education; in the summer of 2019, 11124 took it for
A Levels, 3098 for AS Levels, and 80027 for GCSEs
\cite{jcqalevel19, jcqgcse19}.

In order to assess the ability of the students in the subject, two methods are
used: examination and non exam assessment (NEA) in the form a programming
project. To assess students during exams, exam boards produce questions that
use and ask the student to use a pseudocode that is language agnostic and has
been predefined in the specification of the exam board. This is done for
clarity and consistency among other reasons \cite{h446, j276, j277}.

Such an exam board is OCR: in \textcite{h446, j276, j277} a pseudocode is
defined, in \textcite{j277}, it was renamed to ``OCR Exam Reference Language''.

The problem with having a relatively strictly defined language is that although
it is called a ``pseudocode" (at least in older specifications) and it is
mentioned that ``Learners [...] may provide answers in any style of pseudocode
they choose providing its meaning could be reasonably inferred by a competent
programmer.'', it is often that students lose mark due to the style of
pseudocode they chose not being understood by the examiner for various reasons.
As a result of this, it is preferable for students to write their answers in a
style that is as close as possible to the ``pseudocode'' defined by the exam
board to avoid losing marks.

From here on out, what has been described as the `pseudocode' will now be
referred to as a language this is because, firstly, we believe that as an
inherent result of the language used in OCR exams being defined within the
specification, it is no longer a pseudocode but in fact a programming language.
Secondly, in the newest computer science specification, \textcite{j277}, what
was previously described as a pseudocode, is now known as the ``OCR Exam
Reference Language'' (We suspect it is because of the realisation of point 1 by
OCR although there is no evidence to this).

Unfortunately, learning a language is complicated and one of the best ways to
learn one is to practice with it. However because the language is only defined
in the specifications of exam boards, there is no way to practice using it, as
there is no way to execute any code written using the syntax of this language.

Another problem that stems from the use of this language as described is that
there is no way to check in a reliable way if code written using it is correct.
Whether that is when a student is practicing for exams or when writing exam
papers themselves. In the June 2018 A Level Paper 2, there was a mistake in the
exam paper students had to take, demonstrating that even the most proficient
can make mistakes \cite{ocrpec18}.

% TODO how is computation better than other solutions.

We believe that a solution for the problems described would be to implement the
language, as described in the specifications and as used in exams, such that
users can run code that was written using the language. The problem described
lends itself particularly well to a computational solution and in fact is the
only possible solution as computers are the only way to execute and trace
software in a reliable way: although humans can trace the execution of a
program it is a very error prone operation. Additionally, the purpose of this
language is to check a human's work which inherently means it will have to use
another method than one that is carried out by a human: a computer.

If there was the possibility to run the code, it will allow students to use the
language when going through the GCSE and A Level courses which will allow them
to learn the language well and then be able to use it confidently within the
exam. This will improve their ability and allow them to score higher in exams.
Being able to execute code written in this language will also allow to check
answers when practising giving students practical ways to verify what they are
doing; this is especially important at GCSE where students are not necessarily
confident enough to be able to tell for themselves if something is correct and
why it is correct. Lastly being able to execute code written in this language
will also allow to check code that was written using it for example for the
purpose of exam papers removing the possibility of mistakes creeping up like
they did in the June 2018 A Level paper.

Another advantage of having a working implementation of this language is that
students will no longer need to learn two languages: a programming language and
the OCR Exam Reference Language. They will be able to only learn the OCR Exam
Reference Language because they will now be able to use it as a proper
programming language and write programs using it.

Although this project will focus on the OCR Exam Reference Language, this
section in particular applies to other exam boards. The problems described here
are not specific to OCR.

% TODO reference to the sections

From here on out, the result of this project will be referred to as an
implementation of the language, this is because the specifics of the
implementation have not been well defined yet and will be in the features and
the design section.

\subsection{Stakeholders}

One of the main stakeholders for the project are the users. There will be
many different types of users but a majority of them will fall under one of
four different categories: exam board and resource producers, students, and
teachers.

The exam boards and resource producers will make a similar use of the
implementation of the language: they will use it to create resources, one
mainly in the form of exams and the other in a wide variety of forms: exam
style questions, practice activities and other learning resources.
\Textcite{pattis88} found that 80\% of textbooks implemented binary search
\textbf{in}correctly and the 2018 A Level OCR paper contained an error in the
code they presented students suggesting errors in code presented to students
can arise easily and solutions need to be found. We believe that using an
implementation of the language is one such solution and will reduce the
occurrence of this mistake. Exam boards and resource producers will be able to
use the implementation to verify through testing that correct code is produced
in mark schemes, exam questions, and other resources. Exam boards and resource
producers have a very strong interest in creating high quality material with
the least amount of mistakes in them in order to maintain a reputation which
leads to their product being used and purchased (whether that be exams or
preparation material). Furthermore, exam boards have previously been fined for
mistakes in exams \cite{ofqual20180702} and resource producers could also be
sued if the content they produce lead to students failing their qualifications.
For this reason, using this an implementation of the language will not only
improve the accuracy or resources it will also reduce costs (in forms of fines)
for exam boards and resource producers.

Another group of users of the language will be students who are studying
computer science in secondary school. They will be able to use the
implementation to check their answers to questions as well as to write programs
as part of their learning. We believe that this will help boost their grades in
2 ways: firstly, being able to check their answers reliably will allow them to
answer and check their responses in less time leading to them doing more
effective practice and will allow them learn the fundamentals of programming
rapidly and be more confident with their learning as they can prove that what
they have learned works; secondly, having to learn only a single language will
reduce the amount of learning necessary which will allow them to have a more
focused learning and know the content they need to know better.

Lastly, the language can be used to check the answers of students, by running
the programs using the interpreter and verifying the output. This is a task
performed mainly by exam boards and teachers. Exam boards will be able to use
the language to mark some of the work produced by students in exams reducing
the likelihood of mistakes done by markers and being more lenient as long as
the student wrote a valid program. Teachers will also be able to use it to plan
their lessons and demo some of the programs to their students, making the
lessons more engaging.

In addition to users, stakeholders may include companies and individual who
extend the language for profit or not. This includes developers of editors and
other integrated development environments. For example a company could create
an online platform for students to try the language out or save their code.

\subsection{Existing solutions}

Currently what is done is that when people write code in the OCR Exam Reference
Language they can only check it manually, this can be considered to be a
solution however it is error prone and doesn't provide much, in particular to
students who are not proficient in the language.

There are however other software that have been written in the past that are
much more similar to what this project aims to offer.

\subsubsection{Existing programming languages}

Programming languages are not a new concept, they have been a major subfield of
computer science since its inception and are still one of the major ongoing
areas of research. As part of the project, we will be developing an
interpreter. Interpreters have been written thousands if not millions of times
before, virtually every programming language has an interpreter, as such there
is a lot of documentation and resources explaining how to write interpreters
and programming languages and it is for the most part a solved problem.

In order to develop this programming language we will use \textcite{eopl}, a
textbook that is used in many programming languages university courses around
the world, to guide us.

We will also inspire ourselves from other languages. In particular
\citetitle{python}, and \citetitle{rust} in order to derive the intended
behaviour of the OCR Reference Language when it has not been defined well
enough in the specification. What we mean by that is when we are not sure how
our program should behave we will try to match the behaviour that would be
displayed by rust or python.

The reason for these 2 choices is that python is one of the most popular
programming languages as of the time of this writing and is the one used by
most schools to teach their secondary school students, additionally the OCR
Reference Language is very similar to python and as such we believe that
drawing its behaviour from python is most likely to be what is intended.
However sometimes we will match the behaviour of rust as it is the language we
will use for the implementation and thus it will be simpler and reduce
complexity to match its behaviour than having to implement something else.

\subsubsection{Pseudo Code Interpreter}

\Citetitle{jacobsieradzki18} is an iPad app that allows to execute pseudo code
for OCR exams.

However, it has many disadvantages that we hope this project will address.
Starting with the syntax, it uses a syntax that although is inspired from the
OCR pseudo code guide is not like the OCR pseudocode guide and as a result
cannot be used to learn the language properly nor can it be used to check for
mistake. Another feature of \citetitle{jacobsieradzki18} that makes it
unsuitable to solve the problem demonstrated above is that it is only available
as an iPad app and as a result it cannot be used across a wide variety of
devices and for many different purposes; this ties in with the fact the
language is not implemented like other languages: it is not possible to use it
standalone. For example, when input is asked from the user a special interface
is shown which is not suitable for use as a programming language.

We will be able to use \citetitle{jacobsieradzki18} to inspire a possible user
interface for the implementation.

\subsubsection{Pseudocompiler}

\Citetitle{pseudocompiler} ``is a (pretty) spec-compliant implementation of
OCR's provisional "pseudocode" specification''.

It seems to have the features that this project aims for including a playground
which is a website to test out a language. However, we were not able to use it
and the link to the playground is invalid. Additionally, although it discusses
the possible use of LLVM as a target, for the moment it only targets JavaScript
which means that it requires a JavaScript runtime to execute making it less
cross platform.

Considering there are no instructions on how to use it and no demos or examples
of its uses whatsoever on its homepage, it was not possible for us to look at
its features and as a result we do not have much to go off of.

\subsubsection{Pseudocode-Compiler}

\Citetitle{pseudocode-compiler} is a compiler ``that compiles IGCSE pseudocode
to LLVM IR''.

This project compiles to LLVM IR which allows it to support many platforms, as
many as LLVM supports, however it compiles IGCSE pseudocode which is not
suitable for our use case, as we are targeting the OCR Reference Language.
Additionally it compiling to LLVM IR means that it is not so easily runnable by
the user and will require some additional work before it can be used in the
browser.

\subsubsection{Pseudocode-Transpiler}

\Citetitle{pseudocode-transpiler} is a compiler that ``compiles pseudocode into
python''. It uses regular expressions to evaluate statements.

This project compiles IGCSE pseudocode using regular expressions which is not a
reliable method, additionally, it compiles to python which is itself an
interpreted language (at least its reference implementation is), which means
that running code using this method will be slow and probably inaccurate.

To conclude there are many different approaches to writing an implementation of
any given pseudocode. It is possible to compile to different ``targets'' such
as the JVM, python, LLVM or JavaScript; each have their advantage and
disadvantage, some being more cross-platform than others, more efficient than
others.

It is also possible to interpret the language and there are different types of
user interfaces.

\paragraph{Other projects:}

\begin{itemize}
    \item{https://github.com/Sherlemious/IGCSE-CS-PC-Transpiler}
\end{itemize}

\subsubsection{On LLVM}

LLVM has been mentioned multiple times in this section. It is ``a collection of
modular and reusable compiler and toolchain technologies'' as described by its
website. One of the feature it provides is an intermediate representation (IR)
known as LLVM IR. Many compilers including the rust compiler, the
implementation language, compile the source code given to them to LLVM IR and
then use LLVM to compile this intermediate representation down to machine code.

LLVM will optimise the code and can then compile into many different types of
machine code, it supports a dozen architectures/instruction sets. This allows
those writing compilers to focus on their language rather than having to
implement a back-end to their compiler for every instruction set they want to
support.

We will not be using LLVM as part of this project because it would introduce a
large amount of complexity and unfortunately the documentation for LLVM is
quite sparse.

\subsection{Essential Features}

In of itself, the project is quite self contained and there aren't many
features apart from the core itself: implement a language.

It is possible however to separate the core of the language into different
section; for example, the GCSE features and the A Level (Object-oriented
programming) features can be separated. Considering implementing
object-oriented features is more complex this will allow to have a working
language regardless of how the implementation of other features goes.

Other features which we are unlikely to be able to implement but may be done as
a bonus in order to turn this implementation into a more usable language is
tooling. Here is a list of tooling we could implement although it is quite
unlikely this stage is reached.

\subsubsection{Syntax highlighting}

In order to support syntax highlighting, code editors support various ways to
define syntax, some use tree-sitter such as Atom, or Neovim with tree-sitter
support. Others use their own method of specifying the syntax. Lastly, some
editors use the specification of other editors.

As such implementing syntax highlighting would be a lot of work, as every
editor we plan on supporting would require code to be written for.

Syntax highlighting makes code easier to read as the structure is clearly
separated and keywords, variables names and function definitions stand out from
the rest of the code.

\begin{listing}
	\centering
	\begin{minipage}{.5\textwidth}
		\centering
		\begin{minted}{rust}
fn main() {
    println!("Hello, World!");
}
		\end{minted}
	\end{minipage}%
	\begin{minipage}{.5\textwidth}
		\centering
		\begin{minted}{text}
fn main() {
    println!("Hello, World!");
}
		\end{minted}
	\end{minipage}

	\caption{Side-by-side comparison of syntax highlighted and non-syntax
	highlighted code}
\end{listing}

\subsubsection{Playground}

Many modern programming languages have a `playground', a website on which
people can test out the language without having to install any software. For
example the go programming language and rust have one\cite{rustPlayground,
goPlayground}.

This would allow users to test out or even run programs easily which would
lower the barrier to entry, something that is necessary when the target
audience contains students.

Considering the nature of the language, which will be used to test out simple
pieces of code rather than running production-grade services, there is no
necessity for the users to install the software.

\subsubsection{Language Server}

Introduced in 2016 by Microsoft, the language server protocol is a protocol
used by editors to communicate with software that will indicate to the editor
what diagnostics to display to the user. It allows a single program to be
written for each language, as long as the editor supports the protocol, instead
of a plugin being written for every editor and every language out there.

This means that we could write a language server for the OCR reference language
which would add support for the language in all major editors, instead of
having to support each editor individually, minimising bugs and improving the
quality of diagnostics.

\subsubsection{Additional language syntax}

In addition to the language as defined in specification documents, we could add
additional features and syntax. A feature could be to support other pseudocode
languages such as the one used by other exam boards like \textcite{aqaCS} or
\textcite{wjecCS}, this would allow students taking exams from these exam
boards to benefit from this project as well.

We could also add support for features that would make the language more
productive such as a foreign function interface (FFI) with C, which would allow
to call C code and make use of the wide array of libraries already written in
C. FFI support with C is primordial in the success of a language in particular
a high level language like this one because it allows to perform low level
operations and make use of the thousands of libraries that have been written
and C and would simply be impossible to rewrite in another language due to the
amount of work it would require.

An example of C library that would be useful to have within the language is
\citetitle{sqlite}. This SQL database is used by most schools to teach the
database section of the A level course and as such being able to use it within
the programming language would be highly beneficial. \Citetitle{sqlite} being
made up of more than 100,000 lines of code would be impractical to rewrite in
the language and any attempt would result in a much lower code quality.

An alternative to FFI would be to implement interfaces within the interpreter
however this would require the interpreter to be updated for every library that
needs to be supported and as such is impractical.

\subsection{Limitations}

% TODO: students will probably still need to learn another language alongside

A limitation of this solution which we propose is that although this language
will be usable as a general purpose language, students will likely benefit from
also learning another language that is more widely used and is supported by
more libraries. Learning another language will allow students to have a better
grasp of the concept of programming languages and will allow them to understand
and try out the different programming paradigm and language features, something
that is assessed at A Level. Lastly, students who decide to pursue their
studies in computer science will undoubtedly need to learn multiple programming
languages and so we believe that there is little to gain by learning only a
single one. This means that using this implementation in order to avoid
learning two languages is not necessarily beneficial and is probably
detrimental to students for anything greater than short-term time saving, it is
not something we would recommend to students.

Although the language will allow markers to be more lenient when marking code
written by candidates in exams it will not make the marking easier as it will
still be necessary for other syntaxes used by students to be marked correctly
and additionally it will take additional time for the programs written by
students to be transcribed in a digital format so that it can be executed using
the interpreter.

Another limitation of this solution is that the OCR Exam Reference Language is
a language designed to be as neutral as possible and has as its only intended
purpose to represent simple algorithms for exams. As a result, the language is
very limited and cannot be used for much without extensions that add features
to it. This makes it in combination with its non-existent use unsuitable for
building any complex system above a few hundreds lines of code.

One of the most important features of a language is its community: it allows to
have easily available libraries to make development faster without having to
rewrite code that has already been written before. By using a niche language
like this one, a developer is giving up on all the libraries that can make
their life easier. The language doesn't feature a module system to separate
code into multiple files and would allow code to be separated into libraries
for use by others which means that even with a larger user base, it would be
unlikely that the problem described is ever solved. A solution could be to add
a module extension to the language, however, we do not believe that making the
language popular and usable to write business applications is within our aim
and as such will not implement such a feature.

% TODO: reference the design section here

Lastly, another important part of the user experience when it comes to using a
language is tooling. Tooling improves development time and reduces the learning
curve of a language. Although we hope to have syntax highlighting through
tree-sitter (see Design section) and possibly a language server \cite{lsp}, the
tooling will be greatly reduced compared to other languages which means that
the development experience will be less enjoyable and more difficult, leading
to users not being able to write high quality code, and choosing other
languages in favour of this one.

For languages to be successful and as such useful to know, they need a
disrupting feature or another compelling reason to use it. With the language
developed as part of this project, the compelling reason to use it, is related
to exams (whether that be to prepare for them, or to make them) but there are
no other reasons than that and as such it will not be useful to know the
language beyond the reasons just stated which means some users may not find it
worth it to learn and use this project.

\subsection{Hardware and Software requirements}

The language needs to be widely available (as most programming languages are)
and as a result needs to have the least amounts of requirements as possible.
Due to the implementation of the language being in the form of an interpreter
and there being no low level constructs defined (within the OCR spec), the
language doesn't require to run without an operating system (This would be a
requirement if firmwares, operating system and other low level software was
written using the language). As a result a standard operating system will be
required.

The operating systems that will be primarily supported are Linux, MacOS and
Windows (in that order) however the interpreter will be written in a cross
platform fashion (by using libraries to abstract platform specific code) such
that it is most likely going to work on any other modern operating system such
as the BSDs.

If a playground is offered, a browser implementing the standard browser
specifications should be required, alongside a working internet connection. The
playground version will not have restrictions on the host operating system. The
web version could be implemented using web assembly in which case a modern
browser supporting WebAssembly will be required. If the web version is
implemented by running the interpreter on a server, the server will require one
of the operating systems aforementioned.

There are no hardware requirements other than dependencies on already mentioned
software requirements. Interpreters are not resource intensive programs and can
even execute on most low power micro controllers\cite{micropython}.

Because we will be using rust to implement the project, we will be limited by
the platforms rust support, which is to say we will not be limited as rust
supports all major platforms\cite{rustPlatformSupport}.

\subsection{Success Criteria}

For the main part of this project, the interpreter that will execute programs
written in the OCR reference language, the success criteria would be that the
interpreter works. This means that when given valid code, it should be able to
execute it and return to the user what is expected.

However, this is quite a general definition and within the interpreter they may
be some features of the language that works while others don't and as such we
need to break down this larger success criteria into smaller sub-parts. The
sub-parts can be defined in terms of features of the language.

Following is a list of the features that should be tested to measure how
successful the project was. The list is derived from the pseudocode guide in
\citetitle{h446}:

\begin{enumerate}
	\item Being able to read a file
	\item Working sequential instructions
	\item Comments
	\item Outputting to screen
	\item Variables
	\item Iteration --- Count Controlled
	\item Selection
	\item Logical Operators
	\item Iteration --- Condition Controlled
	\item String Handling
	\item Subroutines
	\item Subroutines --- Passing values by value or by reference
	\item Arrays
	\item Reading from files
	\item Writing to files
	\item Objects --- Attributes
	\item Objects --- Methods
	\item Object --- Access level
	\item Object --- Constructors
	\item Object --- Inheritence
\end{enumerate}

In order to make the success criteria more objective, it would be preferable if
these features can be tested as much as possible in an automatic way to remove
bias. This would also make the testing more efficient.

\subsubsection{Success criteria for optional features}

To consider syntax highlighting, to be complete, for the editors for which syntax
highlighting is implemented, keywords, and structures that make up the language
should be highlighted accordingly. The syntax defined for the syntax
highlighting should have no bugs such that the different elements of the code
are highlighted in a coherent way. If the highlighting is not coherent it would
be confusing for the user and would result in reduced productivity.

For the playground, the language should be usable with as much of the features
of the language being usable from the playground. Some features will be more
difficult to implement as an inherent result of the platform. For example
reading and writing to files on the web makes little to no sense and it is
perfectly acceptable if this is not achieved. However, it can be possible to
implement it for example by having a virtual file system to which users can
upload files.

The success criteria for the language server would involve having produced a
language server that is usable by most editors in particular those of interest
for us are Neovim and VS code. If the language server works for both of these
editors it can be considered that it is stable enough and should work for most
others. The language server should be able to display appropriate errors to the
user and assist them in their development.

For all additional language features, the success criteria would be that the
feature is functional and works as intended.

\section{Design of the interpreter}
\label{sec:design_int}

\subsection{Type of programming language implementation}

There are 2 main ways to be able to write language: as an interpreter or as a
compiler. Additionally there are also different flavours of just-in-time (JIT)
compilers.

Interpreters work by directly executing the instructions indicated by the
program. For example, if in the programming language, there is a print
instruction, the interpreter will print the text corresponding to the operand
of that print instruction.

Compilers work by translating the source code into another type of code.
Generally compilers compile code down to a lower level representation of the
code but sometimes they transform the code into a language of a similar level
of abstraction from the source language, for example to JavaScript. These types
of compilers are usually called ``transpilers''. For example the
\citetitle{nim} compiler compiles Nim source code down to JavaScript or C.
Compilers are generally more difficult to implement as they have greater
complexity and the lower the level of abstraction the target language is the
greater the complexity of the compiler generally is. Ultimately some compilers
compile to machine code, code that can be directly executed on the CPU.

In addition to compilers and interpreters, there are just-in-time compilers
which compile code to machine code as it is executed, often just-in-time
compilers are a hybrid of a compiler and an interpreter, such that code is
interpreted at first and then compiled to obtain a greater performance. This is
how the JavaScript engines that run in major browsers (V8, SpiderMonkey and
JavaScriptCore, for Chromium, Firefox and Safari respectively) are implemented.

For our programming language, we have decided to opt for an interpreter design
due to the language's dynamic nature, the lesser complexity of implementation
of interpreters and the much greater cross-platform compatibility.

\subsection{Language of implementation}

The implementation language will be rust because it is a language the author is
familiar with and because it is a high performance language as it compiles to
machine code. This is very important when writing an interpreter because it
will allow to have acceptable performance. Writing an interpreter in an
interpreted language would accumulate overhead and result in bad performance.

Additionally, Rust supports a very wide array of operating systems and CPU
architectures/instruction set. This is particularly important as we plan on
building a playground which will execute code on the client side using
WebAssembly (wasm)\cite{wasm}, a web standard which defines a bytecode that can
be executed by browsers. As of now very few languages have good support for
WebAssembly, but it is generally considered that rust has be the best support,
even though, it is still not straight forward to use it.

\subsection{Parsing}

Now that we have made the high-level design decisions, we will look at the
implementation of the interpreter itself. Figure
\ref{fig:interpreting_flowchart} shows the major steps involved in the
interpretation of a program.

\begin{figure}
	\centering
	\begin{tikzpicture}[node distance=2cm]
		\node (start) [terminal] {Start};
		\node (parsing) [process, below of=start] {Parsing};
		\node (interpreting) [process, below of=parsing] {Interpreting};
		\node (end) [terminal, below of=interpreting] {End};
		\draw [flowchartarrow] (start) -- (parsing);
		\draw [flowchartarrow] (parsing) -- (interpreting);
		\draw [flowchartarrow] (interpreting) -- (end);
	\end{tikzpicture}
	\caption{The major steps carried out by an interpreter}
	\label{fig:interpreting_flowchart}
\end{figure}

The first step of interpreting any kind of code is parsing. This stage involves
converting text into a structured object which can then be used for other
purposes, most importantly evaluating/interpreting the object to execute the
code it represents. The object generated is known as an abstract syntax tree
(AST) and represents the program to be executed as a tree data structure.

There are numerous methods of writing a parser, they generally fall under two
wide categories, manual parsing, or parsing using parser generators. Parser
generators are programs to which which output a parser given a language
grammar, a definition of the syntax of a language and its structure. The parser
is then capable of parsing the input. On the other hand, when writing parsers
manually instead of having the parser generated for us based on a language
grammar, we write ourselves the code that would parse the input.

At first we were hoping to use \citetitle{treesitter} as our parsing system
because it would give us syntax highlighting inside of editors without having
to write a regex based grammar or another parser. Being able to re-use the
parser used for the language as well as for syntax highlighting increases the
robustness of the software, because a single shared implementation is used and
bugs that are found are fixed for both, and both stay consistent with each
other. Additionally using a parser generator is generally less error prone as
the parser generator is unlikely to produce invalid code and less time
consuming as only a grammar has to be written instead of a parser, something
much more complex.

However in the end we decided to write our own parser because writing
tree-sitter grammars is not an easy task and is described as having ``a
difficult learning curve''\cite{ts_creating_parsers} and tree-sitter loads
language grammars as shared libraries which would have been difficult to use
within the playground from web assembly as the grammar itself would be a web
assembly module in addition to the interpreter which would also be a
WebAssembly module. Lastly, writing a parser is generally not considered to be
the most complex task of writing an interpreter and writing our own gives us
much more flexibility.

This is why we have decided to use a different method for parsing the code. We
settled on using parser combinators with the help of the parser combinator
framework \citetitle{nom}. This library was chosen because it is the most widely
used parsing framework for rust (our implementation language) and the author
has experience having used it while going through \textcite{eopl} to prepare
for this project.

Another advantage of using parser combinators is that they allow to perform
complex transformations during the parsing. For example, it is possible to
transform a switch statement into if statements and else-if statements into
if and else statements during the parsing instead of in a different pass, this
allows to reduce the complexity of subsequent passes at the cost of increasing
the complexity of the parser. Ultimately, we only perform a single pass before
interpreting the abstract syntax tree: parsing, nothing more. Unlike many
interpreters were the source code has to be tokenized before and once the
source code has been parsed it needs to be transformed again into a form that
can be used for interpretation.

This advantage comes directly from another major advantage of using a parser
combinator based method: flexibility. The other major method would be to use a
parser generator library, the method recommended by \textcite{eopl}, such as
\textcite{bison}. The downside of this is that the program will have to be
built upon the structure of the parser and will be limited by it.

\subsubsection{On parser combinators}

Parser combinators are an implementation of the recursive descent algorithm,
they work by chaining functions to parse more complex structures. The recursive
descent algorithm attempts to parse different elements of the input and then
backtracks when it fails, until it eventually succeeds or fail, in which case
it fails to parse the input. This can happen if the input is malformed or if
there's a bug in the parser.

\subsubsection{Language Grammar}

Because we are writing our parser using a parser combinator design, we will
have to define a function for every element we want to parse. In order to do
this we first have to define every element that makes up our language or
otherwise we risk forgetting some elements.

This definition of the structures in a language can be represented in many
different ways, but in our case we will define it as a language grammar. A
language grammar defines all the possible different statements and expressions
found in the language to simplify writing the parser. If we used a method using
parser generators we would normally have given our grammar to the parser
generator so it then generates the parser. In our case, because we are writing
the parser ourselves we are only doing it in order to more easily keep track of
everything that has to be implemented.

The language grammar we define is informal as it is only meant to be read by
humans, unlike one that is used with a parser generator. Each definition is
made up of the left-hand-side and the right-hand-side separated by ``::=''.
The left-hand-side represents the element that is being defined. When an
element is defined multiple times, we are defining the different forms this
element can have. For example a statement can an assignment of a variable but
it can also be a for loop.

The root of the tree is the Program element and from where the parsing starts
with. Comments are not defined in this grammar but they are any text prefixed
by two forward slashes: ``//''.

It can be found at listing \ref{lst:grammar}.

For every element of the of the grammar, and for every variant of every
element, a function will be defined that parses that element using other
functions.

\begin{listing}
	\noindent
	Statement ::= \texttt{global} Identifier \texttt{=} Expression\\
	Statement ::= Identifier \texttt{=} Expression\\
	Statement ::= \texttt{array} Identifier\texttt{[}\{Expression\}\textsuperscript{+(\texttt{,})}\texttt{]}\\
	Statement ::= Expression\\
	Statement ::= \texttt{for} Identifier \texttt{=} Expression \texttt{to} Expression List-of-Statements \texttt{next} Identifier\\
	Statement ::= \texttt{while} Expression List-of-Statements \texttt{endwhile}\\
	Statement ::= \texttt{do} List-of-Statements \texttt{until} Expression\\

	\noindent
	Statement ::= \texttt{if} Expression \texttt{then} List-of-Statements \{\texttt{elseif} Expression \texttt{then} List-of-Statements\}\textsuperscript{*} \{\texttt{else} List-of-Statements\}\textsuperscript{?} \texttt{endif}\\
	Statement ::= \texttt{switch} Expression\texttt{:} \{\texttt{case} Expression\texttt{:} List-of-Statements\}\textsuperscript{*} \{\texttt{default:} List-of-Statements\}\textsuperscript{?} \texttt{endswitch}\\

	\noindent
	Statement ::= \texttt{function} Identifer\texttt{(}\{Identifier\{:byVal | :byRef\}\}\textsuperscript{*(\texttt{,})}\texttt{)} List-of-Statements \texttt{endfunction}\\
	Statement ::= \texttt{procedure} Identifer\texttt{(}\{Identifier\{:byVal | :byRef\}\}\textsuperscript{*(\texttt{,})}\texttt{)} List-of-Statements \texttt{endprocedure}\\
	Statement ::= \texttt{return} Expression\\

	\noindent
	List-of-Statements ::= ()\\
	List-of-Statements ::= (Statement . List-of-Statements)\\

	\noindent
	Expression ::= Constant\\
	Expression ::= Identifer\texttt{(}\{Expression\}\textsuperscript{*(\texttt{,})}\texttt{)}\\
	Expression ::= Identifier\texttt{.}Field\\
	Expression ::= Identifier\texttt{.}Method\texttt{(}\{Expression\}\textsuperscript{*(\texttt{,})}\texttt{)}\\

	\noindent
	Expression ::= Expression \texttt{AND} Expression\\
	Expression ::= Expression \texttt{OR} Expression\\
	Expression ::= \texttt{NOT} Expression\\

	\noindent
	Expression ::= Expression \texttt{==} Expression\\
	Expression ::= Expression \texttt{!=} Expression\\
	Expression ::= Expression \texttt{\textless{}} Expression\\
	Expression ::= Expression \texttt{\textless=} Expression\\
	Expression ::= Expression \texttt{\textgreater{}} Expression\\
	Expression ::= Expression \texttt{\textgreater=} Expression\\

	\noindent
	Expression ::= Expression \texttt{+} Expression\\
	Expression ::= Expression \texttt{-} Expression\\
	Expression ::= Expression \texttt{*} Expression\\
	Expression ::= Expression \texttt{/} Expression\\
	Expression ::= Expression \texttt{MOD} Expression\\
	Expression ::= Expression \texttt{DIV} Expression\\
	Expression ::= Expression \texttt{\textasciicircum{}} Expression\\

	\noindent
	Program ::= List-of-Statements
	\caption{The grammar for our language}
	\label{lst:grammar}
\end{listing}

Using this grammar we are able to declare classes that define possible nodes on
the tree. In our particular implementation, we will use Rust's \texttt{enum}
feature which allows to define objects that can be one of many variant. In our
implementation we will have two types of elements: Statements and Expressions.
Our \texttt{Expression} enum will have all the different types of expression
and the \texttt{Statement} enum will have all the different types of statements
as defined in listing \ref{lst:grammar}. Statements can be put together into a
list known as a list of statements, this represents blocks of codes that can be
found in this language.

The major differences between expression and statements is that expressions
evaluate to a value whereas statements do not evaluate to anything, they only
perform an action. This distinction of evaluating and only performing an
operation also exists in the language in the form of the co-existence of
procedures and functions where in other languages they would be one. In our
implementation we treat them as one with the only difference between the two
being that functions when called return a value whereas statements return
nothing, or to be more precise they return a value indicating that no value was
returned.

Ultimately, because statements can also be return statements that return
values, lists of statements are effectively expressions and so are all
statements that contain a list of expression that they could execute or not.

\subsubsection{Implementation details}

Parser combinators can cause issues when multiple parsers succeed at parsing a
given input. An example of this is numbers, a parser for floating point numbers
will generally succeed at parsing integers and vice versa. In our
implementation we have decided to use the algorithm presented in
\autoref{fig:number_parse_alg}. It allows to parse float and integer literals
in the way the user expects it to happen. The way it works is that if either
parser fails it returns the result of the other parser or otherwise returns the
result of the parser that consumed the post input. Note that our parser
combinators return a \texttt{Result} type which is why it is fine the return
the result of the integer parser even if it failed, this just means the result
will propagate down without affecting the ultimate result.

\begin{figure}
	\centering
	\begin{tikzpicture}
		\node (start) [terminal] {Parse number};
		\node (parse_int) [process, below = 0.7cm of start] {Attempt to parse integer};
		\node (parse_float) [process, below = 0.7cm of parse_int] {Attempt to parse float};
		\node (int_err) [decision, below = 0.7cm of parse_float] {Did integer parsing
		succeed?};
		\node (return_float) [terminal, right of = int_err, node distance=5cm] {Return float};
		\node (float_err) [decision, below = 0.7cm of int_err] {Did float
		parsing succeed?};
		\node (return_int) [terminal, right of = float_err, node distance=5cm] {Return integer};
		\node (which_longest) [decision, below = 0.7cm of float_err] {Did
		integer parsing consume more input than float parsing?};
		\node (return_float2) [terminal, right of = which_longest, node
		distance=5cm] {Return float};
		\node (return_int2) [terminal, below = 0.7cm of which_longest] {Return integer};
		\draw [flowchartarrow] (start) -- (parse_int);
		\draw [flowchartarrow] (parse_int) -- (parse_float);
		\draw [flowchartarrow] (parse_float) -- (int_err);
		\draw [flowchartarrow] (int_err) -- node[anchor=south] {no} (return_float);
		\draw [flowchartarrow] (int_err) -- node[anchor=east] {yes} (float_err);
		\draw [flowchartarrow] (float_err) -- node[anchor=south] {no} (return_int);
		\draw [flowchartarrow] (float_err) -- node[anchor=east] {yes} (which_longest);
		\draw [flowchartarrow] (which_longest) -- node[anchor=south] {no} (return_float2);
		\draw [flowchartarrow] (which_longest) -- node[anchor=east] {yes} (return_int2);
	\end{tikzpicture}
	\caption{Flowchart of the process involved in parsing a number}
	\label{fig:number_parse_alg}
\end{figure}

Many decisions had to be taken in regards to the design of the language itself
because it was never strictly defined in the exam specifications from OCR. For
example the format of identifiers (class, function and variable names) is not
defined. So we decided to have a design similar to most languages (such as
python and rust): identifiers can be made of letters and digits, as well as
underscores and dashes however they cannot start with a digit. The reason most
languages do this and we have decided to follow their decision is because
having an identifier start with a digit makes parsing more difficult as a
integer literal parser could succeed when what is being parsed is not a number
but rather an identifier.

The last two design decisions have been made due to parsers not being mutually
successful (i.e. multiple parsers can succeed for a given input).

\subsection{Interpreting}

To interpret a program we will simply go over the structure of it executing its
statements one-by-one.

In order to deal with state: classes, functions, and variables defined
throughout our program, we will have a \textbf{\texttt{Context}} object that
holds all the state of our program. It will be made of a hash table from
function names to function objects, a hash table of class names to class
objects and lastly, an environment. The environment is a list\footnote{in this
section ``list'' is used as a generic term, however implementation-wise we use
rust's \citetitle{vec} type.} of hash tables mapping from variable names to
values.

Each hash table in the list represents a different stack frame. The first
element is the global scope and each time a function is called a new element is
added.

Because our language supports references, there are multiple ways of storing
values. One of them is to have a list containing the values and then store in
the environment references to the index of the elements in the list. One
problem of this approach is that it doesn't garbage collect elements once they
are unused.

This is why we have decided to use the rust language's built-in types to deal
with garbage collection. Each denoted value is a reference counted value, such
that once there are no references to the value it is dropped and memory is
freed.

To simplify the implementation, values are implemented entirely in rust and use
overloading (using the traits in rust) to make the use of values within the
interpreter easier. This can have downsides as it abstracts away the values
however it means that when writing the interpreter less time is wasted.

Objects are stored as a list of values, each value representing a field in the
object. Overloading works using a method similar to lexical
addressing\footnote{Lexical addressing is a method in which textual variables
are converted into numbers, this allows for improved performance because
variables are now just indices in a list, something that has an order O(1)
lookup}, in that attribute names are converted into indices within the object.

However we do not use lexical addressing anywhere else, this means that strings
are stored in the class objects (that part of the context) and hash tables are
used for everything instead of lists. The reason for this is we have found it
difficult to implement whilst following other resources as preparation for this
project.

\subsection{Testing}

Testing is very important in maintaining stable software that behaves as
intended. It allows to define the behaviour of our software and prevent
regressions from occurring. For this project we will be using automated testing
to test our software because it will allow to consistently tests anything in a
much faster and objective way. It will allow to test hundreds of components in
mere seconds which will be a great productivity boost. By making the friction
of testing so much smaller it also means we will be testing much more often
leading to mistakes being found faster. Lastly, it will allow us to use a
software development process known as test-driven development in which tests
are written before the code it tests is written. Using this approach will
improve productivity because it gives a clear goal during the development
process and also prevents the test to be built around the behaviour of the
already written code rather than the other way around which would mean the
tests are bias and may not be suitable.

Additionally because we will be building the parser first, there will be no
convenient way for a human to test the parser and writing tests would allow to
test the parser, without having to write an interface for a human tester (or
any other way that involves a human in the process of testing the parser). Once
the interpreter is developed, it is then possible for a human to test the
program manually as they can see the result of the program they run.

In order to test the software and validate the success criteria in an objective
way, a testing script \texttt{neasuccess} will be written before the
implementation has started to be written. This test script will run the
implementation with different inputs and verify that the output is the one
expected.

The success test script will be modular and be able to support many different
tests. It will work in the following way: In the \texttt{tests} directory,
there will be files with the extension \texttt{.input} and \texttt{.output}.
The success test script will run the interpreter with as input the content of
the \texttt{.input} files and check if the output is the same as the file with
the same basename but as extension \texttt{.output} file. In order to test the
parser, we will also have \texttt{.ast} files containing a representation of
the AST to which to parser can compare the result to.

An argument can be given to the success test script to only use the tests with
the basename given.

In table \ref{tbl:success_criteria} the success criteria defined in the
analysis are listed alongside the way they will be able to be tested using the
\texttt{neasuccess} script and the test data. The test data will be displayed
with the input on the top/left and the expected output on the bottom/right with
a grey background. It is highly likely that some of the features in the success
criteria will be implemented together rather than sequentially.

The test data given to test for the success criteria are deliberately very
simple so that they only test the success criteria in question, however in
development, we will use much more complex tests when appropriate to test the
entirety of the interpreter at once.

\begin{table}
    \begin{adjustbox}{center}
        \begin{tabular}{|l|l|l|}
            \hline
			Criteria & How to evidence & Code \\
            \hline
            Being able to read a file & Run the interpreter with a file as input & \\
            \hline
			Working sequential instructions & Run \texttt{./neasuccess seq} & Listing \ref{lst:design_seq} \\
            \hline
			Comments & Run \texttt{./neasuccess comments} & Listing \ref{lst:design_comment} \\
            \hline
			Outputting to screen & Run \texttt{./neasuccess print} & Listing \ref{lst:design_print} \\
            \hline
			Variables & Run \texttt{./neasuccess variables} & Listing \ref{lst:design_variables} \\
            \hline
            Iteration --- Count Controlled & Run \texttt{./neasuccess forloop} & Listing \ref{lst:design_for_loop} \\
            \hline
			Selection & Run \texttt{./neasuccess selection} & Listing \ref{lst:design_string_handling} \\
            \hline
			Logical Operators & Run \texttt{./neasuccess logic} & \\
            \hline
            Iteration --- Condition Controlled & Run \texttt{./neasuccess whileloop} & Listing \ref{lst:design_while_loop} \\
            \hline
			String Handling & Run \texttt{./neasuccess strings} & Listing \ref{lst:design_string_handling} \\
            \hline
			Subroutines & Run \texttt{./neasuccess subroutines} & Listing \ref{lst:design_subroutine_run} \\
            \hline
            Subroutines --- Passing values by value or by reference & Run \texttt{./neasuccess byvalue\_byref} & Listing \ref{lst:design_byref} \\
            \hline
			Arrays & Run \texttt{./neasuccess arrays} & Listing \ref{lst:design_subroutine_run} \\
            \hline
			Reading from files & Run \texttt{./neasuccess readfile} & Listing \ref{lst:design_read_from_file} \\
            \hline
			Writing to files & Run \texttt{./neasuccess writefile} & \\
            \hline
			Objects --- Attributes & Run \texttt{./neasuccess attributes} & \\
            \hline
			Objects --- Methods & Run \texttt{./neasuccess methods} & \\
            \hline
			Object --- Access level & Run \texttt{./neasuccess access} & \\
            \hline
			Object --- Constructors & Run \texttt{./neasuccess constructors} & \\
            \hline
			Object --- Inheritence & Run \texttt{./neasuccess inheritance} & \\
            \hline
        \end{tabular}
    \end{adjustbox}
    \caption{Success Criteria}
	\label{tbl:success_criteria}
\end{table}

\begin{listing}
	\inputminted{text}{./prog/prog/test_data/design_seq.input}
	\inputmintedgrey{text}{./prog/prog/test_data/design_seq.output}
	\caption{Test data for executing sequential instructions}
	\label{lst:design_seq}
\end{listing}

\begin{listing}
	\inputminted{text}{./prog/prog/test_data/comment1.input}
	\inputmintedgrey{text}{./prog/prog/test_data/comment1.output}
	\caption{Test data with comment}
	\label{lst:design_comment}
\end{listing}

\begin{listing}
	\begin{minipage}{.5\textwidth}
		\inputminted{text}{./prog/prog/test_data/print.input}%
	\end{minipage}%
	\begin{minipage}{.5\textwidth}
		\inputmintedgrey{text}{./prog/prog/test_data/print.output}
	\end{minipage}
	\caption{Test data for printing}
	\label{lst:design_print}
\end{listing}

\begin{listing}
	\inputminted{text}{./prog/prog/test_data/design_variables.input}
	\inputmintedgrey{text}{./prog/prog/test_data/design_variables.output}
	\caption{Test data for variables}
	\label{lst:design_variables}
\end{listing}

\begin{listing}
	\inputminted{text}{./prog/prog/test_data/for_loop1.input}
	\inputmintedgrey{text}{./prog/prog/test_data/for_loop1.output}
	\caption{Test data for for loops}
	\label{lst:design_for_loop}
\end{listing}

\begin{listing}
	\inputminted{text}{./prog/prog/test_data/design_while.input}
	\inputmintedgrey{text}{./prog/prog/test_data/design_while.output}
	\caption{Test data for while loops}
	\label{lst:design_while_loop}
\end{listing}

\begin{listing}
	\inputminted{text}{./prog/prog/test_data/design_string_handling.input}
	\inputmintedgrey{text}{./prog/prog/test_data/design_string_handling.output}
	\caption{Test data for string handling and selection}
	\label{lst:design_string_handling}
\end{listing}

\begin{listing}
	\inputminted{text}{./prog/prog/test_data/design_byref.input}
	\inputmintedgrey{text}{./prog/prog/test_data/design_byref.output}
	\caption{Test data for passing data by reference and by value}
	\label{lst:design_byref}
\end{listing}

\begin{listing}
	\inputminted{text}{./prog/prog/test_data/design_subroutine_run.input}
	\inputmintedgrey{text}{./prog/prog/test_data/design_subroutine_run.output}
	\caption{Test data for running subroutines and arrays}
	\label{lst:design_subroutine_run}
\end{listing}

\begin{listing}
	\inputminted{text}{./prog/prog/test_data/design_read_from_file.input}
	\inputmintedgrey{text}{./prog/prog/test_data/design_read_from_file.output}
	\caption{Test data to check whether it is possible to read from files}
	\label{lst:design_read_from_file}
\end{listing}

% TODO (don't forget about ./savedstuff.tex)

\section{Design of the playground}

As briefly mentioned at the beginning of the design of the interpreter, by
having the interpreter written in rust allows us to compile it down to
WebAssembly which means that we can then execute our interpreter in the browser
allowing users to run snippets of code.

A major advantage of using this method to implement a playground is that it
doesn't require a complex back-end, a simple web server suffices as we only
need to serve static files. This means we do not have to deal with scaling and
resource usage and there is no risk of vulnerabilities in the sandbox executing
user code as there is no sandbox and no user code is executed on our servers.

Because we only need to serve static files, it means that we can use one of the
many free services available online that will allow us to serve static files.
In our case we will use GitHub Pages to host the playground for no cost. If the
implementation was similar to that used by go or rust, we would have much
higher cost as we would need to pay for a server to host the playground and in
addition to that would not be able to scale to a larger number of users.

Another advantage of this client-side method is that the application can be
interactive, it can print text to the screen in real time and accept input from
the user, something that is rarely seen in traditional playgrounds because it
only displays the result to the user once the code has finished executing.

Another approach to making a playground interactive is to use WebSockets, such
that whenever the user types something it is sent to the server and whenever
the server prints something it is sent by to the user's browser. This is the
approach used by the interactive shell available on python's homepage visible
in figure \ref{fig:python-playground}.

However this approach has some downsides, first of all it is much slower than
our approach as it has to incur the cost of network latency and having to send
every operation over the network. Secondly it is very complex to implement and
requires having servers that are always on and have to deal with a large amount
of state: each user currently using an iterative session is state to keep
track of.

\begin{figure}
	\includegraphics[width=\textwidth]{python-playground}
	\caption{Screenshot of the python online iterative shell}
	\label{fig:python-playground}
\end{figure}

\begin{figure}
	\includegraphics[width=\textwidth]{rust-playground}
	\caption{Screenshot of rust's official playground}
	\label{fig:rust-playground}
\end{figure}

\subsection{Implementation details}

Figure \ref{fig:playground_flow} shows the major steps executed by the
playground. In order to compile our interpreter to WebAssembly we will have a
second crate\footnote{Crates are the name given to packages in Rust} that has
as dependency our interpreter and will have platform specific code for
WebAssembly. This will include dealing with IO on the web which is much
different than natively, as on the web we are not actually printing to a file
but rather modifying the DOM\footnote{Document Object Model, the structure of
the web page}.

This means that our interpreter when printing won't be able to just print
normally otherwise it would not be possible to support this in WebAssembly,
instead we will make it `Write'\footnote{The `Write' trait is the one that will
be used} to some generic object which will be different based on the platform.
This is similar to polymorphism in other languages, except the polymorphism is
done at compile time rather than runtime which is what allows Rust to be such a
high performance language.

\begin{figure}
	\centering
	\begin{tikzpicture}[node distance=2cm]
		\node (start) [terminal] {Website is loaded};
		\node (load_UI) [process, below of=start] {Load user interface};
		\node (load_int) [process, below of=load_UI] {Load wasm module for interpreter};
		\node (wait_for_input) [io, below of=load_int] {Wait for user to submit code};
		\node (interpret) [process, below of=wait_for_input] {Execute program};
		\node (print) [io, below of=interpret] {Print generated output};
		\node (end) [process, below of=print] {Program finishes executing};
		\node (terminate) [terminal, below of = end] {Browser tab is closed};
		\draw [flowchartarrow] (start) -- (load_UI);
		\draw [flowchartarrow] (load_UI) -- (load_int);
		\draw [flowchartarrow] (load_int) -- (wait_for_input);
		\draw [flowchartarrow] (wait_for_input) -- (interpret);
		\draw [flowchartarrow] (interpret) -- (print);
		\coordinate [right = 0.5cm of print] (temp);
		\coordinate [above = 1cm of interpret.north, above of = temp ] (temp1);
		\draw [flowchartline, sloped] (print.east) -- (temp) -- node
		{\midarrow} (temp1) -| (interpret.north);
		\draw [flowchartarrow] (print) -- (end);
		\draw [flowchartarrow, sloped] (end.south) |- ++(3.4cm,-0.5cm) --
		node {\midarrow} ($(wait_for_input.north) + (3.4cm,0.5cm)$) -| (wait_for_input.north);
		\draw [flowchartarrow] (end) -- (terminate);
	\end{tikzpicture}
	\caption{User flow when they visit the playground}
	\label{fig:playground_flow}
\end{figure}

\subsection{Usability features}

The playground will be separated into two sections, an editor to a side and a
pane with the result of executing the program in another pane. In the editing
pane the user will be able to enter their source code and they can then execute
it or print the abstract syntax tree that was produced after parsing their
code. The ability to print abstract syntax tree is beneficial for students to
understand how parsing works and is useful for the development of the project
itself to debug mistakes in parsing.

\subsection{Testing}

Because this is a user facing application it is more difficult to test it in an
automatic manner. Generally to test such web applications a headless browser is
used however we have decided to leave this section untested as it doesn't have
many features and as such wouldn't be too time consuming to test manually. This
is because most of the features are implemented in the interpreter which is
already tested separately, the playground is just a thin wrapper around the
interpreter adding little functionality.

The list of tests to do manually can be found in table
\ref{tbl:playground_tests}.

\begin{table}
	\begin{adjustbox}{center}
	\begin{tabular}{|l|l|l|}
		\hline
		What is being tested & How to test & Success criteria \\
		\hline
		Printing & \makecell[ll]{Enter a simple program \\ and then run it} & Verify that the
		output is correct \\
		\hline
		\makecell[ll]{Errors when given \\ invalid code} & Enter an invalid program &
		\makecell[ll]{Verify that there is an error \\ message indicating where
		in \\ the program a mistake was found} \\
		\hline
		Inputting & \makecell[ll]{Enter a program that asks \\ for the user to
		input data} &
		Verify that inputting data works \\
		\hline
	\end{tabular}
	\end{adjustbox}
	\caption{Tests to do on the playground}
	\label{tbl:playground_tests}
\end{table}

\section{Development}

In order to make development efficient we have used the version control system
\citetitle{git}. This allows us to create snapshots of our software as we move
along the stages of development and allows us to experiment with features which
we can then roll back or accept into our main branch.

\subsection{Stage 1}

In the first stage of development we focused only on the parser. Using the
grammar described in design we wrote the \texttt{struct}\footnote{The
equivalent to classes found in low level languages} for the tree and then wrote
a parser for it, making sure to implement all the possible variants.

In the first version, unlike what was ``promised'' in the design section of
this document we did not write a testing tool and so in order to be able to
test source code we wrote our tests in Rust using its builtin testing
framework. The test compared the AST generated after parsing some code with an
AST that was manually generated before hand.

This first initial version could only parse variables and only had a single
hard-coded test: variable (see listing \ref{lst:first_test}). This test can be
found in the final code listing in \autoref{sec:final_project}. To have
variables we also implemented string literals and integer literals. Whilst
implementing string literals we were faced with a problem that will keep
recurring: how loosely defined the OCR reference language is. In this
particular case, in the specification, quotes for string literals could either
be normal double quotes or slanted double quotes going left or right. We
suspect this may because this was overlooked when writing the specification
however we decided to implement it such that all three types are entirely
equivalent in our language (see \autoref{fig:quote_parser}. Additionally the
language doesn't seem to include escaping either and as such we have not
implemented it.

Our only test passed (see \autoref{fig:stage1_test}) and we could move on to
the following stages of development.

\begin{figure}
	\includegraphics[width=\textwidth]{initial_quote}
	\caption[Screenshot of the initial quote parser supporting all three types of quotes]{Screenshot\footnotemark{} of the initial quote parser supporting all three types of quotes}
	\label{fig:quote_parser}
\end{figure}

\footnotetext{A screenshot had to be taken because we had trouble showing slanted quotes in this document}

\begin{listing}
	\begin{minted}{rust}
#[test]
fn variable_test() {
	assert_eq!(
		program(include_str!("../tests/variable.input")).unwrap().1,
		include!("../tests/variable.ast")
	);
}
	\end{minted}
	\caption{Our very first test}
	\label{lst:first_test}
\end{listing}

\begin{figure}
	\includegraphics[width=\textwidth]{stage1_test}
	\caption{Screenshot of the first test passing}
	\label{fig:stage1_test}
\end{figure}

\subsection{Stage 2}

In the second stage of development we added more tests and generalised our
testing using metaprogramming\footnote{metaprogramming is when code is written
that generates further code, in our case this was done through rust's macro
system} such that test were not manually written but generated automatically.
This allows us to add tests rapidly and in a reliable way. Now it was possible
to just add tests by adding an entry in the ``tests'' directory and then
referencing it in our code with \mintinline{rust}{ast_test!()}, see listing
\autoref{lst:macro_test}. Evidence of the tests passing can be found in
\autoref{fig:stage2_test}. The actual content of the tests can be found in the
final code listing in \autoref{sec:final_project} on page
\pageref{sec:final_project}.

\begin{listing}
	\begin{minted}{rust}
macro_rules! ast_test {
	( $function_name:ident ) => {
		#[test]
		fn $function_name() {
			assert_eq!(
				program(include_str!(concat!(
					"../tests/",
					stringify!($function_name),
					".input"
				)))
				.unwrap()
				.1,
				include!(concat!("../tests/", stringify!($function_name), ".ast"))
			);
		}
	};
}

ast_test!(variable);
ast_test!(variable_quotes);
ast_test!(variable_whitespace);
	\end{minted}
	\caption{The definition of the ast\_test macro and the subsequent use of
	it to define three tests}
	\label{lst:macro_test}
\end{listing}

\begin{figure}
	\includegraphics[width=\textwidth]{stage2_test}
	\caption{Screenshot of two new added tests passing}
	\label{fig:stage2_test}
\end{figure}

\subsection{Stage 3}

We then added support for more language constructs to the parser, namely:
function calls, float literals and for loops.

Previously the integer literal variant was called \texttt{NumberLiteral} and so
we renamed it to \texttt{IntegerLiteral} so it wouldn't be confused with
\texttt{FloatLiteral} because a number could be a float or an integer. For the
float implementation we decided to store it as an \texttt{f64}\footnote{This
type is often known as a \texttt{double} in other languages and represents a
64bit floating point number} instead of an \texttt{f32} to have more
flexibility and because the overhead caused by using a larger float wasn't too
much of an issue as this was not a performance critical language.

\section{Evaluation}

% We could have fuzzed the parser
% we could have used tree-sitter instead
% we could have probably gotten around the problem we had
% lexical addressing
% benchmarking
% no code coverage
% we used a different testing strategy that was much better

\section{Final project}
\label{sec:final_project}

In order to compile the final project, here is a list of dependencies:

% FIXME: do we actually need rust nightly?
\begin{itemize}
	\item Rust (nightly)
	\item Node.js (for playground)
	\item wasm-pack (for playground)
\end{itemize}

Some of the listings in the following section are not displayed correctly. For
example, some lines are too long and go over the page and some of the
characters, in particularly the chess pieces and the curved double quotation
marks are not displayed correctly. To be able to navigate the project, without
these mistakes, here are 2 attachments of it in
\textattachfile{./final_files.zip}{zip} and
\textattachfile{./final_files.tar.gz}{tar.gz} format (some PDF viewer do not
support attachments, Firefox and Adobe Acrobat Reader are known to work,
macOS's Preview and Google Chrome \textbf{do not} work).

\input{./final_files.tex}

\section{NOTES NOT PART OF REPORT}

Note on string literals: the unicode characters `“` and `”` seem to be used to
delimit string literals. Is that normal??

In the examples given, different unicode characters are used, that's a bit
wacky.

Escaping doesn't seem to exist either

We'll assume identifiers cannot start with numbers (see alter, maybe this can
be changed)

What do we consider whitespace? is a zero width space whitespace?

Do we want to implement closures?? (for language? for implementation? for parsing? for interpreting?)

What are valid identifiers? We'll follow C with: only: letters, digits and
underscore, but first character must be letter or underscore.

Test cases shouldn't be called '*.input' they can contain actual programs so
that doesn't make sense.

%We do not have operator precedence (help)

%Rust doesn't support backtracking in macros:
%https://github.com/rust-lang/rust/issues/24827, https://github.com/rust-lang/rust/issues/42838
so we had to inverse the direction of our ops macro

%Use pretty_assertions to speed up AST testing

Fuzz the parser (idk why, we should just do it cause that sounds cool)

Switch statement implemented as a bunch of if else

This language makes no sense. For example, switch statements have a colon after
the expression. WHY?

On (physical) page 39, there is a 1, after `case "B"`, wtf

Switch statement if given complex expression will compute expression at every
check

Log:

%Changed from ../ to CARGO_MANIFEST_DIR

alt((
	value(x, x),
	value(x, x),
	value(x, x),
	value(x, x),
))

was failing to compile. So I had to report it to the authors.

There is no "break" statement for loops.

Array is defined as "array" and "Array" in the spec...

Fields in classes must be defined before methods.

For loops will rewrite the counter variable, so the user can change it.
Pascal prevents compilation of programs where the variable is changed so I
think that's a fine behaviour.

For dealing with when to return a float or integer, we are following python's
behaviour. E.g. division always returns float (exception, thinking logically
seems to have issues with the new code) (update: so I asked Mrs Zeshan to show
me the solution to the homework to be 100\% of the correct. Turns out what I
had was correct. So the issue is with the interpreter or PG Online having
terrible questions/mark schemes.

Power return integer or other depending on various things

Problem, test with stdout
Solution: allow to write to other places than stdout

Problem: numerical values can be ints or floats.
Solution: fail no silently whenever types are somewhat not similar and
comparing the 2 hasn't explicitly been defined.

This behaviour is different than what python does. Python will happily compare
an integer and a string, always returning False.

Another way in which the behaviour is away from python is that when we print a
float, if it doesn't have any decimal place it shows like an int. This is
because we use the rust formatter. Although we have said we try to emulate
python behaviour, we will probably use rust behaviour before.

Programmed wasm support in browser it works!!!! I'm a bit wary of performance
issues with stuff being copied.

Fixed performance issue potentially (idk didn't benchmark) but we still have
the problem that the dom won't redraw in this infinite loop...

Tried using xterm js, reached a problem where the input was corrupted. This was
solved by using .slice(): https://github.com/rustwasm/wasm-bindgen/issues/1668

The problem is that even with xterm js the output doesn't show.

Last solution: using a background worker.

Couldn't load web worker. Turns out it's because Firefox doesn't support web
workers as modules.

The solution is to load it dynamically or smth now it works. It's weird how we
have to receive the message first before we can load the module.

Fixed a bug with integer literal parsing where "-1" would be detected a
variable

Could have used something like https://github.com/mitsuhiko/insta to improve
development speed.

Added a reference type which in the end I had to remove, nevermind, I'll just
extend it, why am I so retarded 😖

We need to implement returning from functions inside of execute\_statements

Add converting functions

\subsection{Where to find example code}

\begin{itemize}
	\item In the specification
	\item Unit 10 Computational thinking, Homework 4 Thinking logically
\end{itemize}

\printbibliography[heading=bibintoc]

\end{document}
